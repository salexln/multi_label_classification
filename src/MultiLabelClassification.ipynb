{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiLabel Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies:\n",
    "#### Python\n",
    "* pip install sklearn\n",
    "* pip install scikit-multilearn\n",
    "* pip install future\n",
    "* pip install python-igraph\n",
    "* python-graph-tool: Use this tutorial to install it on ubuntu https://zhangkaiyuan.com/2018/03/10/Install-graphtools-on-Ubuntu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources: (should be at the bottom)\n",
    "* http://scikit.ml/api/classify.html#ensemble-approaches\n",
    "* http://scikit.ml/\n",
    "* https://en.wikipedia.org/wiki/Multi-label_classification\n",
    "* https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_multilabel_classification(sparse=True, n_labels=20, return_indicator = 'sparse', allow_unlabeled = False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Transformation methods:\n",
    "We will transform multi-label classification problem into single lable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Binary relevance:\n",
    "This baseline approach, amounts to independently training one binary classifier for each label: Given an unseen sample, the combined model then predicts all labels for this sample for which the respective classifiers predict a positive result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65000000000000002"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "\n",
    "# train:\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict:\n",
    "prediction = classifier.predict(X_test)\n",
    "\n",
    "# check accuracy:\n",
    "accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Classifier chains:\n",
    "In this method, each classifier is trained on the output of the previous classifier (when the first one is trained on the input data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "\n",
    "classifier = ClassifierChain(GaussianNB())\n",
    "\n",
    "# train:\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict:\n",
    "prediction = classifier.predict(X_test)\n",
    "\n",
    "# check accuracy:\n",
    "accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Label powerset:\n",
    "This transformation creates one binary classifier for every label combination found in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "classifier = LabelPowerset(GaussianNB())\n",
    "\n",
    "# train:\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict:\n",
    "prediction = classifier.predict(X_test)\n",
    "\n",
    "# check accuracy:\n",
    "accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adapted algorithm\n",
    "Instead of changing the problems, we could change the algorithm to support multi label classification. Exmaple of these algorithms are KNN, desicion trees, boosting, neural networks, ets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Multi Lavel KNN (MLkNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69999999999999996"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "classifier = MLkNN(k=20)\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "prediction = classifier.predict(X_test)\n",
    "\n",
    "# check accuracy\n",
    "accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ensemble learning\n",
    "It is often useful to train more than one model for a subset of labels in multi-label classification, especially for large label spaces - a well-selected smaller label subspace can allow more efficient classification.\n",
    "As rule of thumb, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69999999999999996"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.cluster import IGraphLabelCooccurenceClusterer\n",
    "from skmultilearn.ensemble import LabelSpacePartitioningClassifier\n",
    "\n",
    "# construct base forest classifier\n",
    "base_classifier = RandomForestClassifier()\n",
    "\n",
    "# setup problem transformation approach with sparse matrices for random forest\n",
    "problem_transform_classifier = LabelPowerset(classifier=base_classifier,\n",
    "    require_dense=[False, False])\n",
    "\n",
    "# partition the label space using fastgreedy community detection\n",
    "# on a weighted label co-occurrence graph with self-loops allowed\n",
    "clusterer = IGraphLabelCooccurenceClusterer('fastgreedy', weighted=True,\n",
    "    include_self_edges=True)\n",
    "\n",
    "# setup the ensemble metaclassifier\n",
    "classifier = LabelSpacePartitioningClassifier(problem_transform_classifier, clusterer)\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
